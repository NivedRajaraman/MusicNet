{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pretty_midi\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "import re\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "tf.set_random_seed(42)\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM, Dropout\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.core import Dense, Activation, Dropout, RepeatVector\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import sys\n",
    "import heapq\n",
    "#import seaborn as sns\n",
    "#from pylab import rcParams\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def noteVal(y):\n",
    "    val = y\n",
    "    val = val.split('-', 1)[0]\n",
    "    val = re.sub('Tied', '', val)\n",
    "    return noteList.get(val.lower(), 0)\n",
    "\n",
    "#noteList = {'whole':48,'half':24,'dotted half':16,'triplet':16,'quarter':12,'dotted quarter':8,'eighth':6,'dotted eighth':4, \n",
    "#            'sixteenth':3, 'dotted sixteenth':3, 'thirty second':2, 'triplet thirty second':1, 'sixty fourth':1}\n",
    "\n",
    "noteList = {'whole':24,'half':12,'dotted half':8,'triplet':8,'quarter':6,'dotted quarter':4,'eighth':3,'dotted eighth':3,\n",
    "            'sixteenth':2, 'dotted sixteenth':2, 'thirty second':1, 'triplet thirty second':1, 'sixty fourth':1}\n",
    "    \n",
    "\n",
    "# What should the format hold?\n",
    "# Simplest format is note pitch held for a note value amount of time, not allowing multiple notes at once\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing the dataset\n",
    "The training set is picked up from the open source musicnet dataset that has been published in the numpy _npz_ format  \n",
    "The dataset contains annotations of music compositions from over 330 classical music pieces in 3 different instruments.  \n",
    "The over 1 million annotated labels indicate the precise time of each note in every recording, the instrument that plays  \n",
    "each note, and the note's position in the metrical structure of the composition. The labels are acquired from musical  \n",
    "scores aligned to recordings by the state of the art *dynamic time warping* algorithm. The labels are verified by trained  \n",
    "musicians, with an estimated labeling error rate of 4%\n",
    "\n",
    "The dataset is stored hierarchically as an interval tree, which when queried with a time point provides the annotations  \n",
    "for each note being played by each intrument at that moment. The annotations do not account for the decay in note volume  \n",
    "for the duration it is sustained for (for some instruments), so the note is taken to be at constant volume through its life\n",
    "\n",
    "The dataset is pre-processed and stored back as an *npz* array. The dataset ndarray is stored as binary encoded vectors at  \n",
    "quantized time instant (bars quantized into 24 notes). The vector corresponding to a given 24<sup>th</sup> note has 1's at  \n",
    "all locations where a particular note is being. Thus the ndarray has 2 dimensions:\n",
    "    1. 128 - the total number of midi-note pitches possible for an instrument\n",
    "    2. 24 * #BARS - as each bar is quantized into 24 locations for notes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#(start,end,(instrument,note,measure,beat,note_value))\n",
    "\n",
    "train_data = np.load(open('../mnt/Downloads/musicnet.npz','rb'))\n",
    "\n",
    "fs = 44100\n",
    "\n",
    "print 'Number of recordings: ' + str(len(train_data.files))\n",
    "\n",
    "totalNotesCount = 0\n",
    "BarRoll = {}\n",
    "\n",
    "for idx in train_data:\n",
    "    #X is the audio, Y is the labels\n",
    "    X,Y = train_data[idx]\n",
    "\n",
    "    DURATION = (Y.end())/fs\n",
    "    print \"DURATION = \" + str(DURATION) + \"s\"\n",
    "\n",
    "    Yseq = sorted(Y)\n",
    "\n",
    "    NOTES = []\n",
    "    for y in Yseq:\n",
    "        if (y.data)[0] == 41:\n",
    "            NOTES.append(y)\n",
    "    \n",
    "    print 'Number of notes is: ' + str(len(NOTES))\n",
    "    totalNotesCount += len(NOTES)\n",
    "    if not NOTES:\n",
    "        print 'it is empty, hence going to the next song'\n",
    "        continue\n",
    "    \n",
    "    Measures = (NOTES[-1].data)[2]\n",
    "    print \"Total number of measures is = \" + str(Measures)\n",
    "    PianoRoll = np.zeros( (128, int(24+math.ceil(24*Measures))), dtype='float32' )\n",
    "\n",
    "    for note in NOTES:\n",
    "        #RHS is length of the note value\n",
    "        start = int(round(24*( note.data[2]+note.data[3] )))\n",
    "        PianoRoll[ note.data[1], start:start+noteVal(note.data[4]) ] = 1\n",
    "    \n",
    "    BarRoll[idx] = PianoRoll\n",
    "    print 'done: ' + idx\n",
    "\n",
    "np.savez_compressed('../mnt/Downloads/DATASET.npz', BarRoll=BarRoll)\n",
    "print totalNotesCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressing the data-set to fit in memory\n",
    "Since the dataset is stored sparsely (roughly 1-2%), we further preprocess to fit it in memory. Since not every pitch is  \n",
    "realized in a musical composition (some notes may even lie outside the auditory spectrum), the array is truncated to the  \n",
    "upper and lower pitch range corresponding to where notes are played. This roughly cuts the size of the ndarray in half.\n",
    "\n",
    "We then convert the dataset into a format that makes the training examples and labels more apparent to the neural network.  \n",
    "The dataset is parsed into segments of length **MEMORY** (in this case, we take a full bar (24) as MEMORY) that are offset  \n",
    "by the parameter **OFFSET**, the immediate next **FUTURE** notes are the _labels_ for the data and are what the neural network  \n",
    "would try to predict (for simplicity, we take FUTURE as being 1 24<sup>th</sup> note)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Size = 736416\n",
      "MAXnote = 101\n",
      "MINnote = 51\n",
      "Number of notes = 50\n",
      "Unzipping training label: 1788(with augmentation)\n",
      "Unzipping training label: 1789(with augmentation)\n",
      "Unzipping training label: 2659(with augmentation)\n",
      "Unzipping training label: 1835(with augmentation)\n",
      "Unzipping training label: 2482(with augmentation)\n",
      "Unzipping training label: 2483(with augmentation)\n",
      "Unzipping training label: 2480(with augmentation)\n",
      "Unzipping training label: 2481(with augmentation)\n",
      "Unzipping training label: 2154(with augmentation)\n",
      "Unzipping training label: 2155(with augmentation)\n",
      "Unzipping training label: 2156(with augmentation)\n",
      "Unzipping training label: 2157(with augmentation)\n",
      "Unzipping training label: 2150(with augmentation)\n",
      "Unzipping training label: 2151(with augmentation)\n",
      "Unzipping training label: 2244(with augmentation)\n",
      "Unzipping training label: 2158(with augmentation)\n",
      "Unzipping training label: 2159(with augmentation)\n",
      "Unzipping training label: 2242(with augmentation)\n",
      "Unzipping training label: 2384(with augmentation)\n",
      "Unzipping training label: 2466(with augmentation)\n",
      "Unzipping training label: 2462(with augmentation)\n",
      "Unzipping training label: 2463(with augmentation)\n",
      "Unzipping training label: 1793(with augmentation)\n",
      "Unzipping training label: 1792(with augmentation)\n",
      "Unzipping training label: 1791(with augmentation)\n",
      "Unzipping training label: 1790(with augmentation)\n",
      "Unzipping training label: 1829(with augmentation)\n",
      "Unzipping training label: 1828(with augmentation)\n",
      "Unzipping training label: 1824(with augmentation)\n",
      "Unzipping training label: 2314(with augmentation)\n",
      "Unzipping training label: 2315(with augmentation)\n",
      "Unzipping training label: 2313(with augmentation)\n",
      "Unzipping training label: 2497(with augmentation)\n",
      "Unzipping training label: 1822(with augmentation)\n",
      "Unzipping training label: 2147(with augmentation)\n",
      "Unzipping training label: 2397(with augmentation)\n",
      "Unzipping training label: 2140(with augmentation)\n",
      "Unzipping training label: 2149(with augmentation)\n",
      "Unzipping training label: 2148(with augmentation)\n",
      "Unzipping training label: 2494(with augmentation)\n",
      "Unzipping training label: 1922(with augmentation)\n",
      "Unzipping training label: 1923(with augmentation)\n",
      "Unzipping training label: 1859(with augmentation)\n",
      "Unzipping training label: 2381(with augmentation)\n",
      "Unzipping training label: 2383(with augmentation)\n",
      "Unzipping training label: 2382(with augmentation)\n",
      "Unzipping training label: 2177(with augmentation)\n",
      "Unzipping training label: 2178(with augmentation)\n",
      "Unzipping training label: 2179(with augmentation)\n",
      "Unzipping training label: 2288(with augmentation)\n",
      "Unzipping training label: 2289(with augmentation)\n",
      "Unzipping training label: 1742(with augmentation)\n",
      "Unzipping training label: 2282(with augmentation)\n",
      "Unzipping training label: 2283(with augmentation)\n",
      "Unzipping training label: 2284(with augmentation)\n",
      "Unzipping training label: 2285(with augmentation)\n",
      "Unzipping training label: 1933(with augmentation)\n",
      "Unzipping training label: 1932(with augmentation)\n",
      "Unzipping training label: 1931(with augmentation)\n",
      "Unzipping training label: 2398(with augmentation)\n",
      "Unzipping training label: 1728(with augmentation)\n",
      "Unzipping training label: 1729(with augmentation)\n",
      "Unzipping training label: 1727(with augmentation)\n",
      "Unzipping training label: 2572(with augmentation)\n",
      "Unzipping training label: 2573(with augmentation)\n",
      "Unzipping training label: 2570(with augmentation)\n",
      "Unzipping training label: 2571(with augmentation)\n",
      "Unzipping training label: 2169(with augmentation)\n",
      "Unzipping training label: 2379(with augmentation)\n",
      "Unzipping training label: 2560(with augmentation)\n",
      "Unzipping training label: 2167(with augmentation)\n",
      "Unzipping training label: 2166(with augmentation)\n",
      "Unzipping training label: 2161(with augmentation)\n",
      "Unzipping training label: 2160(with augmentation)\n",
      "Unzipping training label: 2451(with augmentation)\n",
      "Unzipping training label: 1876(with augmentation)\n",
      "Unzipping training label: 2191(with augmentation)\n",
      "Unzipping training label: 1872(with augmentation)\n",
      "Unzipping training label: 1873(with augmentation)\n",
      "Unzipping training label: 1739(with augmentation)\n",
      "Unzipping training label: 1813(with augmentation)\n",
      "Unzipping training label: 1730(with augmentation)\n",
      "Unzipping training label: 2562(with augmentation)\n",
      "Unzipping training label: 2368(with augmentation)\n",
      "Unzipping training label: 2366(with augmentation)\n",
      "Unzipping training label: 2365(with augmentation)\n",
      "Unzipping training label: 2403(with augmentation)\n",
      "Unzipping training label: 2622(with augmentation)\n",
      "Unzipping training label: 1807(with augmentation)\n",
      "Unzipping training label: 2621(with augmentation)\n",
      "Unzipping training label: 2626(with augmentation)\n",
      "Unzipping training label: 2627(with augmentation)\n",
      "Unzipping training label: 2420(with augmentation)\n",
      "Unzipping training label: 2628(with augmentation)\n",
      "Unzipping training label: 2629(with augmentation)\n",
      "Unzipping training label: 1919(with augmentation)\n",
      "Unzipping training label: 1918(with augmentation)\n",
      "Unzipping training label: 2180(with augmentation)\n",
      "Unzipping training label: 2186(with augmentation)\n",
      "Unzipping training label: 1916(with augmentation)\n",
      "Unzipping training label: 2127(with augmentation)\n",
      "Unzipping training label: 2241(with augmentation)\n",
      "Unzipping training label: 2243(with augmentation)\n",
      "Unzipping training label: 2106(with augmentation)\n",
      "Unzipping training label: 2105(with augmentation)\n",
      "Unzipping training label: 2104(with augmentation)\n",
      "Unzipping training label: 2433(with augmentation)\n",
      "Unzipping training label: 2432(with augmentation)\n",
      "Unzipping training label: 2431(with augmentation)\n",
      "Unzipping training label: 1893(with augmentation)\n",
      "Unzipping training label: 2341(with augmentation)\n",
      "Unzipping training label: 1811(with augmentation)\n",
      "Unzipping training label: 1812(with augmentation)\n",
      "Unzipping training label: 2342(with augmentation)\n",
      "Unzipping training label: 2138(with augmentation)\n",
      "Unzipping training label: 2502(with augmentation)\n",
      "Unzipping training label: 2501(with augmentation)\n",
      "Unzipping training label: 2168(with augmentation)\n",
      "Unzipping training label: 2376(with augmentation)\n",
      "Unzipping training label: 2330(with augmentation)\n",
      "Unzipping training label: 1805(with augmentation)\n",
      "Unzipping training label: 2377(with augmentation)\n",
      "Unzipping training label: 2334(with augmentation)\n",
      "Unzipping training label: 2335(with augmentation)\n",
      "Unzipping training label: 2336(with augmentation)\n",
      "Unzipping training label: 2131(with augmentation)\n",
      "Sucessfully unzipped 126 files\n"
     ]
    }
   ],
   "source": [
    "MEMORY = 24\n",
    "OFFSET = 1\n",
    "FUTURE = 1\n",
    "\n",
    "def itercount(val):\n",
    "    return 1+(range(0, val - MEMORY, OFFSET))[-1]/OFFSET\n",
    "\n",
    "D = np.load('../mnt/Downloads/DATASET.npz')\n",
    "PianoRoll = (D['BarRoll']).item()\n",
    "\n",
    "MINnote = 128\n",
    "MAXnote = -1\n",
    "TRsize = 0\n",
    "NUMBEROFNOTES = set()\n",
    "\n",
    "for label in PianoRoll:\n",
    "    song = PianoRoll[label]\n",
    "    locations = set((np.where(song))[0])\n",
    "    NUMBEROFNOTES = NUMBEROFNOTES | locations\n",
    "    MAXnote = np.maximum( MAXnote, max(locations))\n",
    "    MINnote = np.minimum( MINnote, min(locations) )\n",
    "    TRsize = TRsize + itercount(song.shape[1])\n",
    "\n",
    "NOTEspace = int(MAXnote-MINnote+2)\n",
    "\n",
    "print 'Training Data Size = '  + str(TRsize)\n",
    "print 'MAXnote = ' + str(MAXnote)\n",
    "print 'MINnote = ' + str(MINnote)\n",
    "print 'Number of notes = ' + str(len(NUMBEROFNOTES))\n",
    "\n",
    "\n",
    "smp = 0\n",
    "files = 0\n",
    "Input = np.zeros( (TRsize, MEMORY, NOTEspace), dtype='float32' )\n",
    "Output = np.zeros( (TRsize, FUTURE*NOTEspace), dtype='float32')\n",
    "\n",
    "for label in PianoRoll:\n",
    "    song = PianoRoll[label]\n",
    "    print 'Unzipping training label: ' + label + '(with augmentation)'\n",
    "    files = files+1\n",
    "    for idx in range(0, song.shape[1] - MEMORY, OFFSET):\n",
    "        cnt = min(idx,song.shape[1]-MEMORY-FUTURE)\n",
    "        for i in range(0,FUTURE):\n",
    "            Output[smp, i*NOTEspace:(i+1)*NOTEspace] = song[MINnote-1:MAXnote+1,cnt+MEMORY+i]\n",
    "        Input[smp, :, :] = (song[MINnote-1:MAXnote+1,cnt:cnt+MEMORY]).transpose()\n",
    "        smp+=1\n",
    "\n",
    "print 'Sucessfully unzipped ' +str(files)+ ' files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(736416, 24, 52)\n",
      "(736416, 52)\n"
     ]
    }
   ],
   "source": [
    "print Input.shape\n",
    "print Output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callback for real-time accuracy plot for Keras model\n",
    "Keras Callback to plot validation set and training set accuracy for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "class PlotLosses(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.invHdist = []\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.invHdist.append(logs.get('inv_MSE_hamming_distance'))\n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        self.fig, self.ax = plt.subplots(nrows=1, ncols=2,figsize=(20,10))\n",
    "        \n",
    "        self.ax[0].plot(self.x, self.losses, label=\"loss\")\n",
    "        self.ax[0].plot(self.x, self.val_losses, label=\"val_loss\")\n",
    "        self.ax[0].legend(loc=\"right\")\n",
    "\n",
    "        self.ax[1].plot(self.x, self.invHdist, label=\"inv_MSE_hamming_distance\")\n",
    "        self.ax[1].legend(loc=\"upper right\")\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "plot_losses = PlotLosses()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture\n",
    "The model we use for predicting future notes is a single layer LSTM with 256 input neurons. To prevent overfitting, a  \n",
    "dropout of 20% is added at the output. The output later is fully connected of size **FUTURE***NOTEspace (number of  \n",
    "notes between the highest and lowest observed pitch in the dataset). The output layer is a simple sigmoid classifier  \n",
    "which would generate probabilities independently for each note which we can round to generate the prediction for  \n",
    "the next note.\n",
    "\n",
    "The loss function used is categorical cross-entropy. This is allowable for multi-labelled data (as in this case) as the  \n",
    "trainer is heavily penalized for incorrectly predicting all the activated locations in a vector. The optimizer used is the  \n",
    "Adam Optimizer with Nesterov Momentum that various sources [1,2,3] have established performs well on LSTM  \n",
    "network training. The accuracy criterion being measured is a custom variant of top-K categorical accuracy, which is  \n",
    "a bit more forgiving because it only checks that the note with highest predicted probability matches with at least  \n",
    "one of the top 4 notes in the true note spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in os.listdir('checkpoints/'):\n",
    "    os.remove(os.path.join('checkpoints/', f))\n",
    "\n",
    "#from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import keras.backend as K\n",
    "from keras.utils import plot_model\n",
    "\n",
    "def inv_MSE_hamming_distance(y_true, y_pred):\n",
    "    return K.mean(K.abs(y_true) - K.abs(y_true - K.round(y_pred)), axis=-1)\n",
    "\n",
    "# instantiate model\n",
    "model = Sequential()\n",
    "\n",
    "# input layer\n",
    "model.add(LSTM(256, input_shape=(MEMORY, NOTEspace), return_sequences=True)) #, kernel_initializer='Zeros'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# hidden layer 1\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(FUTURE*NOTEspace))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['categorical_accuracy', inv_MSE_hamming_distance])\n",
    "\n",
    "# checkpoint\n",
    "filepath=\"checkpoints/weights-improvement-{epoch:02d}-{loss:.2f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=False, mode='auto')\n",
    "\n",
    "plot_model(model, to_file='model.png', show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the model to the training data\n",
    "The sample data is split into training and validation sets in an 80:20 ratio  \n",
    "Batch size is chosen as 128 and the model is trained for 20 epochs  \n",
    "Shuffling is enabled on the input dataset due to the way it has been generated  \n",
    "Checkpointing is enabled while training due to the long training time per epoch (~30 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 589132 samples, validate on 147284 samples\n",
      "Epoch 1/20\n",
      " 33792/589132 [>.............................] - ETA: 23:44 - loss: 0.0881 - categorical_accuracy: 0.0229 - inv_MSE_hamming_distance: -0.0030"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "history = model.fit(Input, Output, validation_split=0.2, batch_size=128, epochs=20, shuffle=True, callbacks=[checkpointer, plot_losses]).history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model to disk\n",
    "The model is saved in the *HDF5* format which is good for storing (and compressing) sparse data/ model weights  \n",
    "The model architecture is stored as a *yaml* file which allows easy analysis of the design post training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "model_yaml = model.to_yaml()\n",
    "with open(\"tmp/model.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.hdf5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading model\n",
    "If the same model trained from before is used, then this cell can be skipped  \n",
    "If a different model is used, then it can be loaded, providing the correct yaml  \n",
    "architecture and HDF5 model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "\n",
    "from keras.models import model_from_yaml\n",
    "\n",
    "yaml_file = open('tmp/model.yaml', 'r')\n",
    "loaded_model_yaml = yaml_file.read()\n",
    "yaml_file.close()\n",
    "model = model_from_yaml(loaded_model_yaml)\n",
    "# load weights into new model\n",
    "model.load_weights(\"checkpoints-new/weights-improvement-08-0.02.hdf5\") #model.hdf5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post training analysis of the model\n",
    "A new segment of music can be input to the model (1 bar) in the template format in *bar.csv*  \n",
    "The cell below picks up a single bar of music, and uses the trained model to generate an  \n",
    "estimate for the next bar of music. The generation process is sequential, in that each 24<sup>th</sup>  \n",
    "note is generated sequentially and appended to the input bar to generate the next 24<sup>th</sup> note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]), array([18, 18, 18, 18, 18, 18, 21, 21, 21, 21, 21, 21, 24]))\n",
      "(array([0, 0, 0, 0, 0]), array([0, 1, 2, 3, 4]), array([24, 24, 24, 24, 24]))\n"
     ]
    }
   ],
   "source": [
    "# Model has only been trained for true notes in the range MINnote to MAXnote (in a width = NOTEspace)\n",
    "from fractions import Fraction\n",
    "\n",
    "pianoBar=None\n",
    "pianoBar = np.zeros((1,MEMORY,NOTEspace), dtype='float32')\n",
    "\n",
    "def prepareBar(pathToMusicTxt):\n",
    "    print 'BAR    DUR    PITCH'\n",
    "    with open(pathToMusicTxt, 'r') as csvfile:\n",
    "        fileIn = csv.reader(csvfile, delimiter=',')\n",
    "        for line in fileIn:\n",
    "            notePosition = int(24*float(Fraction(line[0])))\n",
    "            noteLength   = noteVal(line[1])\n",
    "            noteFreq     = int(line[2])\n",
    "            print str(notePosition/24.0)+'\\t'+str(noteLength/24.0)+'\\t'+str(noteFreq)\n",
    "            pianoBar[0, notePosition:notePosition+noteLength, noteFreq-MINnote] = 1\n",
    "\n",
    "\n",
    "#prepareBar('bar.csv')\n",
    "pianoBar[0,:,:]=Input[133333,:,:]\n",
    "originalPianoBar=pianoBar\n",
    "\n",
    "print np.where(pianoBar)[1:3]\n",
    "\n",
    "for iteration in range(0,MEMORY,FUTURE):\n",
    "    indices=[]\n",
    "    future=np.reshape( model.predict(pianoBar, batch_size=1, verbose=0), (NOTEspace,FUTURE) )\n",
    "    indices = np.where(np.round(future))\n",
    "    np.sort(future, axis=0)\n",
    "    #if np.ndarray.max(future) > 0.5:\n",
    "        #print 'ooooooooooooooo'\n",
    "    #else:\n",
    "        #print '---------------'\n",
    "    pianoBar[0,0:MEMORY-FUTURE,:] = pianoBar[0,FUTURE:MEMORY,:]\n",
    "    pianoBar[0,MEMORY-FUTURE:MEMORY,:] = np.zeros((FUTURE,pianoBar.shape[2]))\n",
    "    for i,j in zip(indices[1],indices[0]):\n",
    "        # print i,j\n",
    "        pianoBar[0,MEMORY-FUTURE+i,j] = 1\n",
    "        \n",
    "print np.where(pianoBar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "No available audio device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-6bc1abb00b81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mMyMIDI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrequency\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m44100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4096\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmusic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mgen.mid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmusic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: No available audio device"
     ]
    }
   ],
   "source": [
    "from midiutil import MIDIFile\n",
    "import pygame\n",
    "import time\n",
    "\n",
    "track    = 0\n",
    "channel  = 0\n",
    "time     = 0    # In beats\n",
    "duration = 1    # In beats\n",
    "tempo    = 90   # In BPM (quarter notes per minute)\n",
    "volume   = 100  # 0-127, as per the MIDI standard\n",
    "\n",
    "MyMIDI = MIDIFile(1)  # One track, defaults to format 1 (tempo track is created\n",
    "                      # automatically)\n",
    "MyMIDI.addTempo(track, time, 24*tempo/4)\n",
    "\n",
    "L = np.where(originalPianoBar)[1]\n",
    "V = np.where(originalPianoBar)[2]\n",
    "for i in range(0,len(L)):\n",
    "    MyMIDI.addNote(track, channel, MINnote+L[i], L[i], duration, volume)\n",
    "    \n",
    "L = np.where(pianoBar)[1]\n",
    "V = np.where(pianoBar)[2]    \n",
    "for i in range(0,len(L)):\n",
    "    MyMIDI.addNote(track, channel, MINnote+L[i], 24 + L[i], duration, volume)\n",
    "    \n",
    "with open(\"Mgen.mid\", \"w\") as output_file:\n",
    "    MyMIDI.writeFile(output_file)\n",
    "\n",
    "pygame.mixer.init(frequency=44100, size=-16, channels=2, buffer=4096)\n",
    "pygame.mixer.music.load(\"Mgen.mid\")\n",
    "pygame.mixer.music.play(loops=0, start=0.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
